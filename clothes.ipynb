{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "fashion_train_df = pd.read_csv('data/fashion-mnist-train.csv', sep=',')\n",
    "fashion_test_df = pd.read_csv('data/fashion-mnist-test.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the data\n",
    "\n",
    "fashion_train_df.head()\n",
    "fashion_train_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = np.array(fashion_train_df, dtype=np.int32)\n",
    "testing = np.array(fashion_test_df, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(1,60000)\n",
    "plt.imshow(training[i,1:].reshape((28,28)))\n",
    "\n",
    "plt.imshow(training[i,1:].reshape((28,28)), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = training[i,0]\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_grid = 15\n",
    "l_grid = 15\n",
    "\n",
    "fig, axes = plt.subplots(l_grid, w_grid, figsize = (17,17))\n",
    "axes = axes.ravel()\n",
    "n_training = len(training)\n",
    "\n",
    "for i in np.arange(0, w_grid * l_grid):\n",
    "    index = np.random.randint(0, n_training)\n",
    "    axes[i].imshow(training[index,1:].reshape((28,28)))\n",
    "    axes[i].set_title(training[index,0], fontsize = 8)\n",
    "    axes[i].axis('off')\n",
    "plt.subplots_adjust(hspace=0.4)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tain = training[:,1:]/255\n",
    "y_train = training[:,0]\n",
    "\n",
    "x_test = testing[:,1:]/255\n",
    "y_test = testing[:,0]\n",
    "\n",
    "x_tain[0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pegando os canais de cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tain = x_tain.reshape(x_tain.shape[0], *(28,28,1))\n",
    "x_test = x_test.reshape(x_test.shape[0], *(28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrução e treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 18:14:03.183158: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-06 18:14:03.183211: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-06 18:14:03.183264: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fedora): /proc/driver/nvidia/version does not exist\n",
      "2023-03-06 18:14:03.184297: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                36928     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "cnn = models.Sequential()\n",
    "\n",
    "#adicionando a primeira camada de convolução com 32 filtros de 3x3 e função de ativação relu e a entrada de 28x28x1\n",
    "\n",
    "cnn.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)))\n",
    "\n",
    "#adicionando a camada com o max pooling de 2x2 para reduzir a dimensionalidade da imagem e evitar overfitting e a camada de dropout para zerar 20% dos neurônios para evitar overfitting\n",
    "cnn.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "\n",
    "#adicionando a primeira camada de convolução com 64 filtros de 3x3 e função de ativação relu e a entrada de 28x28x1\n",
    "\n",
    "cnn.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "\n",
    "#adicionando a camada com o max pooling de 2x2 para reduzir a dimensionalidade da imagem e evitar overfitting e a camada de dropout para zerar 20% dos neurônios para evitar overfitting\n",
    "cnn.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "cnn.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "\n",
    "#adicionando a camada de flatten para transformar a imagem em um vetor para ser usado na rede neural\n",
    "\n",
    "cnn.add(layers.Flatten())\n",
    "\n",
    "#adicionando a camada densa com 64 neurônios e função de ativação relu para a camada escondida\n",
    "\n",
    "cnn.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "#adicionando a camada dense com 10 neurônios e função de ativação softmax para a camada de saída que vai retornar a probabilidade de cada classe\n",
    "\n",
    "cnn.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "118/118 [==============================] - 21s 164ms/step - loss: 0.8759 - accuracy: 0.6818 - val_loss: 0.5528 - val_accuracy: 0.7874\n",
      "Epoch 2/150\n",
      "118/118 [==============================] - 16s 136ms/step - loss: 0.4957 - accuracy: 0.8205 - val_loss: 0.4677 - val_accuracy: 0.8254\n",
      "Epoch 3/150\n",
      "118/118 [==============================] - 16s 139ms/step - loss: 0.4245 - accuracy: 0.8464 - val_loss: 0.4126 - val_accuracy: 0.8515\n",
      "Epoch 4/150\n",
      "118/118 [==============================] - 17s 141ms/step - loss: 0.3858 - accuracy: 0.8608 - val_loss: 0.3792 - val_accuracy: 0.8631\n",
      "Epoch 5/150\n",
      "118/118 [==============================] - 15s 125ms/step - loss: 0.3576 - accuracy: 0.8725 - val_loss: 0.3754 - val_accuracy: 0.8613\n",
      "Epoch 6/150\n",
      "118/118 [==============================] - 16s 136ms/step - loss: 0.3381 - accuracy: 0.8791 - val_loss: 0.3263 - val_accuracy: 0.8840\n",
      "Epoch 7/150\n",
      "118/118 [==============================] - 16s 137ms/step - loss: 0.3186 - accuracy: 0.8864 - val_loss: 0.3177 - val_accuracy: 0.8841\n",
      "Epoch 8/150\n",
      "118/118 [==============================] - 16s 132ms/step - loss: 0.3020 - accuracy: 0.8916 - val_loss: 0.3159 - val_accuracy: 0.8847\n",
      "Epoch 9/150\n",
      "118/118 [==============================] - 15s 131ms/step - loss: 0.2920 - accuracy: 0.8940 - val_loss: 0.2936 - val_accuracy: 0.8946\n",
      "Epoch 10/150\n",
      "118/118 [==============================] - 16s 133ms/step - loss: 0.2774 - accuracy: 0.9007 - val_loss: 0.2891 - val_accuracy: 0.8942\n",
      "Epoch 11/150\n",
      "118/118 [==============================] - 19s 159ms/step - loss: 0.2669 - accuracy: 0.9043 - val_loss: 0.2818 - val_accuracy: 0.8983\n",
      "Epoch 12/150\n",
      "118/118 [==============================] - 18s 151ms/step - loss: 0.2597 - accuracy: 0.9058 - val_loss: 0.2780 - val_accuracy: 0.9003\n",
      "Epoch 13/150\n",
      "118/118 [==============================] - 18s 153ms/step - loss: 0.2513 - accuracy: 0.9093 - val_loss: 0.2651 - val_accuracy: 0.9041\n",
      "Epoch 14/150\n",
      "118/118 [==============================] - 18s 154ms/step - loss: 0.2409 - accuracy: 0.9133 - val_loss: 0.2610 - val_accuracy: 0.9020\n",
      "Epoch 15/150\n",
      "118/118 [==============================] - 18s 155ms/step - loss: 0.2314 - accuracy: 0.9171 - val_loss: 0.2549 - val_accuracy: 0.9057\n",
      "Epoch 16/150\n",
      "118/118 [==============================] - 18s 152ms/step - loss: 0.2266 - accuracy: 0.9176 - val_loss: 0.2660 - val_accuracy: 0.9006\n",
      "Epoch 17/150\n",
      "118/118 [==============================] - 18s 150ms/step - loss: 0.2190 - accuracy: 0.9209 - val_loss: 0.2576 - val_accuracy: 0.9086\n",
      "Epoch 18/150\n",
      "118/118 [==============================] - 18s 155ms/step - loss: 0.2122 - accuracy: 0.9226 - val_loss: 0.2470 - val_accuracy: 0.9093\n",
      "Epoch 19/150\n",
      "118/118 [==============================] - 18s 152ms/step - loss: 0.2057 - accuracy: 0.9243 - val_loss: 0.2444 - val_accuracy: 0.9108\n",
      "Epoch 20/150\n",
      "118/118 [==============================] - 18s 151ms/step - loss: 0.1986 - accuracy: 0.9281 - val_loss: 0.2493 - val_accuracy: 0.9083\n",
      "Epoch 21/150\n",
      "118/118 [==============================] - 18s 150ms/step - loss: 0.1905 - accuracy: 0.9307 - val_loss: 0.2514 - val_accuracy: 0.9076\n",
      "Epoch 22/150\n",
      "118/118 [==============================] - 18s 150ms/step - loss: 0.1847 - accuracy: 0.9334 - val_loss: 0.2487 - val_accuracy: 0.9090\n",
      "Epoch 23/150\n",
      "118/118 [==============================] - 18s 149ms/step - loss: 0.1765 - accuracy: 0.9359 - val_loss: 0.2672 - val_accuracy: 0.9046\n",
      "Epoch 24/150\n",
      "118/118 [==============================] - 18s 148ms/step - loss: 0.1732 - accuracy: 0.9377 - val_loss: 0.2532 - val_accuracy: 0.9090\n",
      "Epoch 25/150\n",
      "118/118 [==============================] - 17s 147ms/step - loss: 0.1699 - accuracy: 0.9382 - val_loss: 0.2570 - val_accuracy: 0.9103\n",
      "Epoch 26/150\n",
      "118/118 [==============================] - 16s 138ms/step - loss: 0.1657 - accuracy: 0.9399 - val_loss: 0.2502 - val_accuracy: 0.9123\n",
      "Epoch 27/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 0.1594 - accuracy: 0.9420 - val_loss: 0.2425 - val_accuracy: 0.9150\n",
      "Epoch 28/150\n",
      "118/118 [==============================] - 16s 136ms/step - loss: 0.1509 - accuracy: 0.9449 - val_loss: 0.2412 - val_accuracy: 0.9110\n",
      "Epoch 29/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 0.1492 - accuracy: 0.9454 - val_loss: 0.2421 - val_accuracy: 0.9158\n",
      "Epoch 30/150\n",
      "118/118 [==============================] - 16s 135ms/step - loss: 0.1435 - accuracy: 0.9476 - val_loss: 0.2439 - val_accuracy: 0.9153\n",
      "Epoch 31/150\n",
      "118/118 [==============================] - 16s 138ms/step - loss: 0.1363 - accuracy: 0.9512 - val_loss: 0.2490 - val_accuracy: 0.9143\n",
      "Epoch 32/150\n",
      "118/118 [==============================] - 16s 136ms/step - loss: 0.1349 - accuracy: 0.9516 - val_loss: 0.2485 - val_accuracy: 0.9146\n",
      "Epoch 33/150\n",
      "118/118 [==============================] - 16s 133ms/step - loss: 0.1295 - accuracy: 0.9536 - val_loss: 0.2568 - val_accuracy: 0.9119\n",
      "Epoch 34/150\n",
      "118/118 [==============================] - 16s 132ms/step - loss: 0.1218 - accuracy: 0.9562 - val_loss: 0.2611 - val_accuracy: 0.9150\n",
      "Epoch 35/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 0.1182 - accuracy: 0.9572 - val_loss: 0.2624 - val_accuracy: 0.9130\n",
      "Epoch 36/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 0.1141 - accuracy: 0.9584 - val_loss: 0.2667 - val_accuracy: 0.9144\n",
      "Epoch 37/150\n",
      "118/118 [==============================] - 15s 131ms/step - loss: 0.1109 - accuracy: 0.9604 - val_loss: 0.2624 - val_accuracy: 0.9160\n",
      "Epoch 38/150\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 0.1054 - accuracy: 0.9613 - val_loss: 0.2605 - val_accuracy: 0.9168\n",
      "Epoch 39/150\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 0.0988 - accuracy: 0.9642 - val_loss: 0.2879 - val_accuracy: 0.9110\n",
      "Epoch 40/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 0.1027 - accuracy: 0.9624 - val_loss: 0.2726 - val_accuracy: 0.9138\n",
      "Epoch 41/150\n",
      "118/118 [==============================] - 15s 128ms/step - loss: 0.0949 - accuracy: 0.9654 - val_loss: 0.2855 - val_accuracy: 0.9135\n",
      "Epoch 42/150\n",
      "118/118 [==============================] - 15s 128ms/step - loss: 0.0901 - accuracy: 0.9671 - val_loss: 0.2920 - val_accuracy: 0.9142\n",
      "Epoch 43/150\n",
      "118/118 [==============================] - 15s 128ms/step - loss: 0.0874 - accuracy: 0.9685 - val_loss: 0.3035 - val_accuracy: 0.9083\n",
      "Epoch 44/150\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 0.0820 - accuracy: 0.9704 - val_loss: 0.3002 - val_accuracy: 0.9137\n",
      "Epoch 45/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 0.0801 - accuracy: 0.9711 - val_loss: 0.3136 - val_accuracy: 0.9148\n",
      "Epoch 46/150\n",
      "118/118 [==============================] - 15s 127ms/step - loss: 0.0755 - accuracy: 0.9726 - val_loss: 0.3016 - val_accuracy: 0.9159\n",
      "Epoch 47/150\n",
      "118/118 [==============================] - 15s 125ms/step - loss: 0.0702 - accuracy: 0.9752 - val_loss: 0.3209 - val_accuracy: 0.9092\n",
      "Epoch 48/150\n",
      "118/118 [==============================] - 15s 126ms/step - loss: 0.0669 - accuracy: 0.9761 - val_loss: 0.3318 - val_accuracy: 0.9103\n",
      "Epoch 49/150\n",
      "118/118 [==============================] - 15s 127ms/step - loss: 0.0631 - accuracy: 0.9779 - val_loss: 0.3393 - val_accuracy: 0.9083\n",
      "Epoch 50/150\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 0.0659 - accuracy: 0.9764 - val_loss: 0.3388 - val_accuracy: 0.9121\n",
      "Epoch 51/150\n",
      "118/118 [==============================] - 15s 124ms/step - loss: 0.0635 - accuracy: 0.9774 - val_loss: 0.3360 - val_accuracy: 0.9132\n",
      "Epoch 52/150\n",
      "118/118 [==============================] - 15s 124ms/step - loss: 0.0524 - accuracy: 0.9824 - val_loss: 0.3397 - val_accuracy: 0.9142\n",
      "Epoch 53/150\n",
      "118/118 [==============================] - 15s 124ms/step - loss: 0.0541 - accuracy: 0.9809 - val_loss: 0.3458 - val_accuracy: 0.9129\n",
      "Epoch 54/150\n",
      "118/118 [==============================] - 16s 132ms/step - loss: 0.0549 - accuracy: 0.9806 - val_loss: 0.3458 - val_accuracy: 0.9135\n",
      "Epoch 55/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 0.0506 - accuracy: 0.9826 - val_loss: 0.3536 - val_accuracy: 0.9139\n",
      "Epoch 56/150\n",
      "118/118 [==============================] - 16s 135ms/step - loss: 0.0522 - accuracy: 0.9814 - val_loss: 0.3653 - val_accuracy: 0.9126\n",
      "Epoch 57/150\n",
      "118/118 [==============================] - 16s 136ms/step - loss: 0.0452 - accuracy: 0.9846 - val_loss: 0.3911 - val_accuracy: 0.9059\n",
      "Epoch 58/150\n",
      "118/118 [==============================] - 16s 139ms/step - loss: 0.0456 - accuracy: 0.9840 - val_loss: 0.3860 - val_accuracy: 0.9112\n",
      "Epoch 59/150\n",
      "118/118 [==============================] - 16s 133ms/step - loss: 0.0404 - accuracy: 0.9864 - val_loss: 0.4175 - val_accuracy: 0.9108\n",
      "Epoch 60/150\n",
      "118/118 [==============================] - 16s 136ms/step - loss: 0.0400 - accuracy: 0.9862 - val_loss: 0.3970 - val_accuracy: 0.9110\n",
      "Epoch 61/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 0.0365 - accuracy: 0.9876 - val_loss: 0.4060 - val_accuracy: 0.9146\n",
      "Epoch 62/150\n",
      "118/118 [==============================] - 16s 136ms/step - loss: 0.0413 - accuracy: 0.9852 - val_loss: 0.3980 - val_accuracy: 0.9151\n",
      "Epoch 63/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 0.0316 - accuracy: 0.9891 - val_loss: 0.4227 - val_accuracy: 0.9121\n",
      "Epoch 64/150\n",
      "118/118 [==============================] - 15s 128ms/step - loss: 0.0342 - accuracy: 0.9886 - val_loss: 0.4299 - val_accuracy: 0.9134\n",
      "Epoch 65/150\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 0.0299 - accuracy: 0.9898 - val_loss: 0.4307 - val_accuracy: 0.9128\n",
      "Epoch 66/150\n",
      "118/118 [==============================] - 18s 150ms/step - loss: 0.0328 - accuracy: 0.9885 - val_loss: 0.4541 - val_accuracy: 0.9103\n",
      "Epoch 67/150\n",
      "118/118 [==============================] - 18s 151ms/step - loss: 0.0275 - accuracy: 0.9906 - val_loss: 0.4789 - val_accuracy: 0.9139\n",
      "Epoch 68/150\n",
      "118/118 [==============================] - 17s 141ms/step - loss: 0.0302 - accuracy: 0.9898 - val_loss: 0.4689 - val_accuracy: 0.9111\n",
      "Epoch 69/150\n",
      "118/118 [==============================] - 17s 141ms/step - loss: 0.0332 - accuracy: 0.9882 - val_loss: 0.4731 - val_accuracy: 0.9127\n",
      "Epoch 70/150\n",
      "118/118 [==============================] - 18s 148ms/step - loss: 0.0335 - accuracy: 0.9881 - val_loss: 0.4753 - val_accuracy: 0.9112\n",
      "Epoch 71/150\n",
      "118/118 [==============================] - 16s 134ms/step - loss: 0.0274 - accuracy: 0.9904 - val_loss: 0.4780 - val_accuracy: 0.9088\n",
      "Epoch 72/150\n",
      "118/118 [==============================] - 16s 132ms/step - loss: 0.0195 - accuracy: 0.9941 - val_loss: 0.4987 - val_accuracy: 0.9143\n",
      "Epoch 73/150\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 0.0155 - accuracy: 0.9956 - val_loss: 0.5104 - val_accuracy: 0.9114\n",
      "Epoch 74/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 0.5217 - val_accuracy: 0.9113\n",
      "Epoch 75/150\n",
      "118/118 [==============================] - 17s 144ms/step - loss: 0.0155 - accuracy: 0.9954 - val_loss: 0.5223 - val_accuracy: 0.9130\n",
      "Epoch 76/150\n",
      "118/118 [==============================] - 18s 151ms/step - loss: 0.0194 - accuracy: 0.9939 - val_loss: 0.5278 - val_accuracy: 0.9091\n",
      "Epoch 77/150\n",
      "118/118 [==============================] - 18s 151ms/step - loss: 0.0197 - accuracy: 0.9935 - val_loss: 0.5570 - val_accuracy: 0.9084\n",
      "Epoch 78/150\n",
      "118/118 [==============================] - 18s 152ms/step - loss: 0.0215 - accuracy: 0.9921 - val_loss: 0.5936 - val_accuracy: 0.9058\n",
      "Epoch 79/150\n",
      "118/118 [==============================] - 18s 148ms/step - loss: 0.0229 - accuracy: 0.9919 - val_loss: 0.5792 - val_accuracy: 0.9106\n",
      "Epoch 80/150\n",
      "118/118 [==============================] - 16s 134ms/step - loss: 0.0266 - accuracy: 0.9903 - val_loss: 0.5992 - val_accuracy: 0.9125\n",
      "Epoch 81/150\n",
      "118/118 [==============================] - 16s 140ms/step - loss: 0.0283 - accuracy: 0.9897 - val_loss: 0.5663 - val_accuracy: 0.9080\n",
      "Epoch 82/150\n",
      "118/118 [==============================] - 15s 126ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 0.5566 - val_accuracy: 0.9132\n",
      "Epoch 83/150\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 0.0159 - accuracy: 0.9950 - val_loss: 0.5866 - val_accuracy: 0.9087\n",
      "Epoch 84/150\n",
      "118/118 [==============================] - 16s 137ms/step - loss: 0.0234 - accuracy: 0.9922 - val_loss: 0.5745 - val_accuracy: 0.9111\n",
      "Epoch 85/150\n",
      "118/118 [==============================] - 16s 136ms/step - loss: 0.0241 - accuracy: 0.9915 - val_loss: 0.6037 - val_accuracy: 0.9083\n",
      "Epoch 86/150\n",
      "118/118 [==============================] - 17s 148ms/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 0.5900 - val_accuracy: 0.9119\n",
      "Epoch 87/150\n",
      "118/118 [==============================] - 16s 140ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.6036 - val_accuracy: 0.9119\n",
      "Epoch 88/150\n",
      "118/118 [==============================] - 15s 131ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.6222 - val_accuracy: 0.9139\n",
      "Epoch 89/150\n",
      "118/118 [==============================] - 16s 135ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.6317 - val_accuracy: 0.9083\n",
      "Epoch 90/150\n",
      "118/118 [==============================] - 17s 140ms/step - loss: 0.0214 - accuracy: 0.9926 - val_loss: 0.6488 - val_accuracy: 0.9073\n",
      "Epoch 91/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 0.0207 - accuracy: 0.9926 - val_loss: 0.6346 - val_accuracy: 0.9110\n",
      "Epoch 92/150\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 0.0212 - accuracy: 0.9927 - val_loss: 0.6573 - val_accuracy: 0.9081\n",
      "Epoch 93/150\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 0.0202 - accuracy: 0.9932 - val_loss: 0.6314 - val_accuracy: 0.9094\n",
      "Epoch 94/150\n",
      "118/118 [==============================] - 15s 131ms/step - loss: 0.0160 - accuracy: 0.9944 - val_loss: 0.6944 - val_accuracy: 0.9060\n",
      "Epoch 95/150\n",
      "118/118 [==============================] - 15s 128ms/step - loss: 0.0206 - accuracy: 0.9927 - val_loss: 0.6360 - val_accuracy: 0.9108\n",
      "Epoch 96/150\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.6474 - val_accuracy: 0.9102\n",
      "Epoch 97/150\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.6568 - val_accuracy: 0.9109\n",
      "Epoch 98/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.6695 - val_accuracy: 0.9129\n",
      "Epoch 99/150\n",
      "118/118 [==============================] - 15s 131ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6743 - val_accuracy: 0.9131\n",
      "Epoch 100/150\n",
      "118/118 [==============================] - 15s 131ms/step - loss: 8.7894e-04 - accuracy: 1.0000 - val_loss: 0.6809 - val_accuracy: 0.9135\n",
      "Epoch 101/150\n",
      "118/118 [==============================] - 16s 133ms/step - loss: 7.4648e-04 - accuracy: 1.0000 - val_loss: 0.6943 - val_accuracy: 0.9141\n",
      "Epoch 102/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 6.6487e-04 - accuracy: 1.0000 - val_loss: 0.7001 - val_accuracy: 0.9136\n",
      "Epoch 103/150\n",
      "118/118 [==============================] - 15s 131ms/step - loss: 6.2152e-04 - accuracy: 1.0000 - val_loss: 0.7071 - val_accuracy: 0.9142\n",
      "Epoch 104/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 5.4517e-04 - accuracy: 1.0000 - val_loss: 0.7128 - val_accuracy: 0.9143\n",
      "Epoch 105/150\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 5.0455e-04 - accuracy: 1.0000 - val_loss: 0.7206 - val_accuracy: 0.9136\n",
      "Epoch 106/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 5.2634e-04 - accuracy: 1.0000 - val_loss: 0.7225 - val_accuracy: 0.9152\n",
      "Epoch 107/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 4.3671e-04 - accuracy: 1.0000 - val_loss: 0.7244 - val_accuracy: 0.9136\n",
      "Epoch 108/150\n",
      "118/118 [==============================] - 15s 128ms/step - loss: 4.0590e-04 - accuracy: 1.0000 - val_loss: 0.7358 - val_accuracy: 0.9141\n",
      "Epoch 109/150\n",
      "118/118 [==============================] - 15s 128ms/step - loss: 3.9514e-04 - accuracy: 1.0000 - val_loss: 0.7395 - val_accuracy: 0.9140\n",
      "Epoch 110/150\n",
      "118/118 [==============================] - 16s 132ms/step - loss: 3.6830e-04 - accuracy: 1.0000 - val_loss: 0.7424 - val_accuracy: 0.9151\n",
      "Epoch 111/150\n",
      "118/118 [==============================] - 15s 131ms/step - loss: 3.4766e-04 - accuracy: 1.0000 - val_loss: 0.7491 - val_accuracy: 0.9149\n",
      "Epoch 112/150\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 3.1615e-04 - accuracy: 1.0000 - val_loss: 0.7540 - val_accuracy: 0.9144\n",
      "Epoch 113/150\n",
      "118/118 [==============================] - 16s 132ms/step - loss: 3.0774e-04 - accuracy: 1.0000 - val_loss: 0.7623 - val_accuracy: 0.9141\n",
      "Epoch 114/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 2.9897e-04 - accuracy: 1.0000 - val_loss: 0.7666 - val_accuracy: 0.9145\n",
      "Epoch 115/150\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 2.8092e-04 - accuracy: 1.0000 - val_loss: 0.7716 - val_accuracy: 0.9140\n",
      "Epoch 116/150\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 2.5769e-04 - accuracy: 1.0000 - val_loss: 0.7825 - val_accuracy: 0.9144\n",
      "Epoch 117/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 2.4610e-04 - accuracy: 1.0000 - val_loss: 0.7879 - val_accuracy: 0.9148\n",
      "Epoch 118/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 2.3101e-04 - accuracy: 1.0000 - val_loss: 0.7904 - val_accuracy: 0.9142\n",
      "Epoch 119/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 2.1283e-04 - accuracy: 1.0000 - val_loss: 0.7975 - val_accuracy: 0.9149\n",
      "Epoch 120/150\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 2.1113e-04 - accuracy: 1.0000 - val_loss: 0.8015 - val_accuracy: 0.9141\n",
      "Epoch 121/150\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 1.9373e-04 - accuracy: 1.0000 - val_loss: 0.8050 - val_accuracy: 0.9146\n",
      "Epoch 122/150\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 1.8533e-04 - accuracy: 1.0000 - val_loss: 0.8119 - val_accuracy: 0.9144\n",
      "Epoch 123/150\n",
      "118/118 [==============================] - 15s 128ms/step - loss: 1.6548e-04 - accuracy: 1.0000 - val_loss: 0.8159 - val_accuracy: 0.9147\n",
      "Epoch 124/150\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 1.5676e-04 - accuracy: 1.0000 - val_loss: 0.8257 - val_accuracy: 0.9144\n",
      "Epoch 125/150\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 1.4989e-04 - accuracy: 1.0000 - val_loss: 0.8313 - val_accuracy: 0.9146\n",
      "Epoch 126/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 1.4104e-04 - accuracy: 1.0000 - val_loss: 0.8417 - val_accuracy: 0.9138\n",
      "Epoch 127/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 1.2875e-04 - accuracy: 1.0000 - val_loss: 0.8446 - val_accuracy: 0.9138\n",
      "Epoch 128/150\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 1.2426e-04 - accuracy: 1.0000 - val_loss: 0.8457 - val_accuracy: 0.9147\n",
      "Epoch 129/150\n",
      "118/118 [==============================] - 15s 131ms/step - loss: 1.1294e-04 - accuracy: 1.0000 - val_loss: 0.8551 - val_accuracy: 0.9142\n",
      "Epoch 130/150\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 1.1168e-04 - accuracy: 1.0000 - val_loss: 0.8621 - val_accuracy: 0.9144\n",
      "Epoch 131/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 1.1447e-04 - accuracy: 1.0000 - val_loss: 0.8642 - val_accuracy: 0.9140\n",
      "Epoch 132/150\n",
      "118/118 [==============================] - 15s 131ms/step - loss: 9.7627e-05 - accuracy: 1.0000 - val_loss: 0.8741 - val_accuracy: 0.9142\n",
      "Epoch 133/150\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 9.0803e-05 - accuracy: 1.0000 - val_loss: 0.8794 - val_accuracy: 0.9138\n",
      "Epoch 134/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 8.5201e-05 - accuracy: 1.0000 - val_loss: 0.8842 - val_accuracy: 0.9141\n",
      "Epoch 135/150\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 7.5939e-05 - accuracy: 1.0000 - val_loss: 0.8936 - val_accuracy: 0.9149\n",
      "Epoch 136/150\n",
      "118/118 [==============================] - 15s 131ms/step - loss: 8.9255e-05 - accuracy: 1.0000 - val_loss: 0.9006 - val_accuracy: 0.9150\n",
      "Epoch 137/150\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 8.6498e-05 - accuracy: 1.0000 - val_loss: 0.9039 - val_accuracy: 0.9134\n",
      "Epoch 138/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 6.6815e-05 - accuracy: 1.0000 - val_loss: 0.9110 - val_accuracy: 0.9139\n",
      "Epoch 139/150\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 6.1397e-05 - accuracy: 1.0000 - val_loss: 0.9209 - val_accuracy: 0.9140\n",
      "Epoch 140/150\n",
      "118/118 [==============================] - 15s 128ms/step - loss: 5.6645e-05 - accuracy: 1.0000 - val_loss: 0.9254 - val_accuracy: 0.9138\n",
      "Epoch 141/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 5.9151e-05 - accuracy: 1.0000 - val_loss: 0.9318 - val_accuracy: 0.9140\n",
      "Epoch 142/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 4.9666e-05 - accuracy: 1.0000 - val_loss: 0.9397 - val_accuracy: 0.9138\n",
      "Epoch 143/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 4.5575e-05 - accuracy: 1.0000 - val_loss: 0.9437 - val_accuracy: 0.9134\n",
      "Epoch 144/150\n",
      "118/118 [==============================] - 15s 131ms/step - loss: 4.5322e-05 - accuracy: 1.0000 - val_loss: 0.9526 - val_accuracy: 0.9135\n",
      "Epoch 145/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 0.1601 - accuracy: 0.9613 - val_loss: 0.3836 - val_accuracy: 0.8850\n",
      "Epoch 146/150\n",
      "118/118 [==============================] - 15s 130ms/step - loss: 0.1903 - accuracy: 0.9305 - val_loss: 0.3632 - val_accuracy: 0.9015\n",
      "Epoch 147/150\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 0.1090 - accuracy: 0.9589 - val_loss: 0.4268 - val_accuracy: 0.9041\n",
      "Epoch 148/150\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 0.0729 - accuracy: 0.9718 - val_loss: 0.4949 - val_accuracy: 0.9069\n",
      "Epoch 149/150\n",
      "118/118 [==============================] - 15s 131ms/step - loss: 0.0499 - accuracy: 0.9811 - val_loss: 0.5074 - val_accuracy: 0.9076\n",
      "Epoch 150/150\n",
      "118/118 [==============================] - 15s 129ms/step - loss: 0.0366 - accuracy: 0.9863 - val_loss: 0.5458 - val_accuracy: 0.9055\n"
     ]
    }
   ],
   "source": [
    "#compilando o modelo com o otimizador adam, função de perda sparse_categorical_crossentropy e métrica de acurácia \n",
    "\n",
    "cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 150\n",
    " \n",
    "history = cnn.fit(x_tain, y_train, batch_size=512, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 13ms/step - loss: 0.5458 - accuracy: 0.9055\n"
     ]
    }
   ],
   "source": [
    "evaluation = cnn.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5457804203033447, 0.9054999947547913]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "predict_x = cnn.predict(x_test)\n",
    "predicted_classes = np.argmax(np.round(predict_x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 8, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 8, 1], dtype=int32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_grid = 5\n",
    "l_grid = 5\n",
    "\n",
    "fig, axes = plt.subplots(l_grid, w_grid, figsize = (12,12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "\n",
    "for i in np.arange(0, w_grid * l_grid):\n",
    "  \n",
    "    axes[i].imshow(training[index,1:].reshape((28,28)))\n",
    "    axes[i].set_title(training[index,0], fontsize = 8)\n",
    "    axes[i].axis('off')\n",
    "plt.subplots_adjust(hspace=0.4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
